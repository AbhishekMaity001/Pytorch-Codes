{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN in Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [02:33<00:00, 15.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking accuracy on Train Data!!... \n",
      "57724/60000 with accuracy 0.9599999785423279\n",
      " Checking accuracy on Test Data!!  \n",
      "9663/10000 with accuracy 0.9700000286102295\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Setting device to CUDA (optional)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, in_channels=1, num_classes=10):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=8, kernel_size=(3,3), stride=(1,1), padding=(1,1))\n",
    "        self.pool = nn.MaxPool2d(kernel_size=(2,2), stride=(2,2))\n",
    "        self.conv2 = nn.Conv2d(in_channels=8,out_channels=16, kernel_size=(3,3), stride=(1,1), padding=(1,1))\n",
    "        self.fc1 = nn.Linear(16*7*7, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.fc1(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "# model = CNN()\n",
    "# x = torch.randn(299, 1, 28, 28) # 299 examples, 1 channel, 28 x 28 size\n",
    "# print(model(x).shape)\n",
    "\n",
    "# Hyperparameters setting\n",
    "in_channels = 1\n",
    "num_classes = 10\n",
    "learning_rate = 0.0001\n",
    "batch_size = 64\n",
    "num_epochs = 10\n",
    "\n",
    "# Load the Data Train & Test\n",
    "train_dataset = datasets.MNIST(root='dataset/', train=True, transform=transforms.ToTensor(), download=True)\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_dataset = datasets.MNIST(root='dataset/', train=False, transform=transforms.ToTensor(), download=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Initialize the Network\n",
    "model = CNN().to(device)\n",
    "\n",
    "# Loss and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train the Network\n",
    "for epoch in tqdm.tqdm(range(num_epochs)):\n",
    "    for batch_idx, (data, targets) in enumerate(train_loader):\n",
    "        \n",
    "        # Convert the data to the CUDA for faster training\n",
    "        data = data.to(device=device)\n",
    "        targets = targets.to(device=device)\n",
    "        \n",
    "        # Flattening the data\n",
    "#         data = data.reshape(data.shape[0], -1)\n",
    "        \n",
    "        # Forward\n",
    "        scores = model(data)\n",
    "        loss = criterion(scores, targets)\n",
    "        \n",
    "        # Backward\n",
    "        optimizer.zero_grad() # so that they dont store the gradrients\n",
    "        loss.backward() # gradients computed here\n",
    "        \n",
    "        # gradient steps \n",
    "        optimizer.step() # here we update the weights based on the gradients computed on top loss.backward()\n",
    "        \n",
    "        \n",
    "# Check Accuracy on training & test set \n",
    "\n",
    "def check_accuracy(loader, model):\n",
    "    if loader.dataset.train:\n",
    "        print(\"Checking accuracy on Train Data!!... \")\n",
    "    else:\n",
    "        print(\" Checking accuracy on Test Data!!  \")\n",
    "    \n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval() # let the model know that it is in evaluation mode\n",
    "    \n",
    "    # to let the model know that you dont have to compute the gradients while doing the tesing/accuracy checking\n",
    "    with torch.no_grad():\n",
    "        for x,y in loader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            \n",
    "#             x = x.reshape(x.shape[0], -1) # Flattening\n",
    "            \n",
    "            scores = model(x)\n",
    "            _, predictions = scores.max(1)\n",
    "            num_correct += (predictions == y).sum()\n",
    "            num_samples += predictions.size(0)\n",
    "            \n",
    "        print('{}/{} with accuracy {}'.format(num_correct, num_samples, np.round(num_correct/num_samples, 2)))\n",
    "        \n",
    "    model.train()    \n",
    "    \n",
    "check_accuracy(train_loader, model)\n",
    "check_accuracy(test_loader, model)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
