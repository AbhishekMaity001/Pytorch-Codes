{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a53ac36f",
   "metadata": {},
   "source": [
    "# Bi-Directional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4c56e0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [01:40<00:00, 20.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking accuracy on Train Data!!... \n",
      "Accuracy on training set: 98.581665\n",
      " Checking accuracy on Test Data!!  \n",
      "Accuracy on test set: 98.12\n"
     ]
    }
   ],
   "source": [
    "# Imports \n",
    "import torch\n",
    "import numpy as np\n",
    "import tqdm\n",
    "\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "# Hyperparameters setting\n",
    "input_size = 28\n",
    "sequence_length = 28\n",
    "num_layers = 2\n",
    "hidden_size = 256\n",
    "num_classes = 10\n",
    "learning_rate = 0.005\n",
    "batch_size = 64\n",
    "num_epochs = 5\n",
    "\n",
    "\n",
    "class BRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(BRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(hidden_size*2, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers*2, x.size(0), self.hidden_size).to(device)\n",
    "        c0 = torch.zeros(self.num_layers*2, x.size(0), self.hidden_size).to(device)\n",
    "        \n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        \n",
    "        return out\n",
    "\n",
    "# Load the Data Train & Test\n",
    "train_dataset = datasets.MNIST(root='dataset/', train=True, transform=transforms.ToTensor(), download=True)\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_dataset = datasets.MNIST(root='dataset/', train=False, transform=transforms.ToTensor(), download=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True)\n",
    "        \n",
    "# Initialize the Network\n",
    "model = BRNN(input_size, hidden_size, num_layers, num_classes).to(device)\n",
    "\n",
    "# Loss and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train the Network\n",
    "for epoch in tqdm.tqdm(range(num_epochs)):\n",
    "    for batch_idx, (data, targets) in enumerate(train_loader):\n",
    "        \n",
    "        # Convert the data to the CUDA for faster training\n",
    "        data = data.to(device=device).squeeze(1) # bcoz MNIST has 1x28x28 but RNN expects N x 28 x 28 ---.squeeze(1) will remove 1 from that particular axis\n",
    "        targets = targets.to(device=device)\n",
    "        \n",
    "        # Flattening the data\n",
    "#         data = data.reshape(data.shape[0], -1)\n",
    "        \n",
    "        # Forward\n",
    "        scores = model(data)\n",
    "        loss = criterion(scores, targets)\n",
    "        \n",
    "        # Backward\n",
    "        optimizer.zero_grad() # so that they dont store the gradrients\n",
    "        loss.backward() # gradients computed here\n",
    "        \n",
    "        # gradient steps \n",
    "        optimizer.step() # here we update the weights based on the gradients computed on top loss.backward()\n",
    "        \n",
    "        \n",
    "# Check Accuracy on training & test set \n",
    "\n",
    "def check_accuracy(loader, model):\n",
    "    if loader.dataset.train:\n",
    "        print(\"Checking accuracy on Train Data!!... \")\n",
    "    else:\n",
    "        print(\" Checking accuracy on Test Data!!  \")\n",
    "    \n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval() # let the model know that it is in evaluation mode\n",
    "    \n",
    "    # to let the model know that you dont have to compute the gradients while doing the tesing/accuracy checking\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=device).squeeze(1)\n",
    "            y = y.to(device=device)\n",
    "            \n",
    "             # x = x.reshape(x.shape[0], -1) # Flattening\n",
    "            \n",
    "            scores = model(x)\n",
    "            _, predictions = scores.max(1)\n",
    "            num_correct += (predictions == y).sum()\n",
    "            num_samples += predictions.size(0)\n",
    "            \n",
    "        # print('{}/{} with accuracy {}'.format(num_correct, num_samples, (num_correct/num_samples)*100, 2))\n",
    "        \n",
    "    model.train()\n",
    "    return num_correct/num_samples\n",
    "    \n",
    "\n",
    "print(f\"Accuracy on training set: {check_accuracy(train_loader, model)*100:2f}\")\n",
    "print(f\"Accuracy on test set: {check_accuracy(test_loader, model)*100:.2f}\")        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d7b8ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
