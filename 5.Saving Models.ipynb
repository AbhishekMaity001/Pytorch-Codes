{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53ac616c",
   "metadata": {},
   "source": [
    "# Saving the Models after Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b93d095",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                                                                                                                                 | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Checkpoint ==>\n",
      "Saving Checkpoint ==> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█████████████████████████████████▌                                                                                                                                                                       | 1/6 [00:04<00:22,  4.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at epoch 0 is 2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███████████████████████████████████████████████████████████████████                                                                                                                                      | 2/6 [00:08<00:17,  4.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at epoch 1 is 1.71\n",
      "Saving Checkpoint ==> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                    | 3/6 [00:13<00:13,  4.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at epoch 2 is 1.35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                   | 4/6 [00:17<00:08,  4.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at epoch 3 is 1.03\n",
      "Saving Checkpoint ==> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                 | 5/6 [00:22<00:04,  4.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at epoch 4 is 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:26<00:00,  4.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at epoch 5 is 0.67\n",
      "Checking accuracy on Train Data!!... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 84.281662\n",
      " Checking accuracy on Test Data!!  \n",
      "Accuracy on test set: 85.57\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import tqdm\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Setting device to CUDA (optional)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, in_channels=1, num_classes=10):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=8, kernel_size=(3,3), stride=(1,1), padding=(1,1))\n",
    "        self.pool = nn.MaxPool2d(kernel_size=(2,2), stride=(2,2))\n",
    "        self.conv2 = nn.Conv2d(in_channels=8,out_channels=16, kernel_size=(3,3), stride=(1,1), padding=(1,1))\n",
    "        self.fc1 = nn.Linear(16*7*7, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.fc1(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "def save_checkpoint(state, filename=\"my_checkpoint.pth.tar\"):\n",
    "    print(\"Saving Checkpoint ==> \")\n",
    "    torch.save(state, filename)\n",
    "    \n",
    "def load_checkpoint(checkpoint):\n",
    "    print(\"Loading Checkpoint ==>\")\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    # IF YOU HAVE SAVED MORE THINGS LIKE ACCURACY SO KINDLY LOAD THOSE ITEMS FROM DICTIONARY\n",
    "\n",
    "    \n",
    "# model = CNN()\n",
    "# x = torch.randn(299, 1, 28, 28) # 299 examples, 1 channel, 28 x 28 size\n",
    "# print(model(x).shape)\n",
    "\n",
    "# Hyperparameters setting\n",
    "in_channels = 1\n",
    "num_classes = 10\n",
    "learning_rate = 1e-4\n",
    "batch_size = 1024\n",
    "num_epochs = 6\n",
    "load_model = True\n",
    "\n",
    "# Load the Data Train & Test\n",
    "train_dataset = datasets.MNIST(root='dataset/', train=True, transform=transforms.ToTensor(), download=True)\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_dataset = datasets.MNIST(root='dataset/', train=False, transform=transforms.ToTensor(), download=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "# Initialize the Network\n",
    "model = CNN().to(device)\n",
    "\n",
    "# LOSS & OPTIMIZER\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "if load_model:\n",
    "    load_checkpoint(torch.load(\"my_checkpoint.pth.tar\"))\n",
    "\n",
    "# Train the Network\n",
    "for epoch in tqdm.tqdm(range(num_epochs)):\n",
    "    losses = [] # FOR STORING THE LOSSES\n",
    "    \n",
    "    if epoch%2 == 0:\n",
    "        checkpoint = {'state_dict' : model.state_dict(), 'optimizer' : optimizer.state_dict()} # YOU CAN STORE OTHERS LIKE ACC ALSO\n",
    "        save_checkpoint(checkpoint)\n",
    "    \n",
    "    for batch_idx, (data, targets) in enumerate(train_loader):\n",
    "        \n",
    "        # Convert the data to the CUDA for faster training\n",
    "        data = data.to(device=device)\n",
    "        targets = targets.to(device=device)\n",
    "        \n",
    "        # Flattening the data\n",
    "        # data = data.reshape(data.shape[0], -1)\n",
    "        \n",
    "        # Forward\n",
    "        scores = model(data)\n",
    "        loss = criterion(scores, targets)\n",
    "        losses.append(loss.item()) # APPENDING THE LOSS\n",
    "        \n",
    "        # Backward\n",
    "        optimizer.zero_grad() # so that they dont store the gradrients\n",
    "        loss.backward() # gradients computed here\n",
    "        \n",
    "        # gradient steps \n",
    "        optimizer.step() # here we update the weights based on the gradients computed on top loss.backward()\n",
    "        \n",
    "    mean_loss = sum(losses)/len(losses)\n",
    "    print(\"Loss at epoch {} is {}\".format(epoch, np.round(mean_loss, 2)))\n",
    "        \n",
    "        \n",
    "# Check Accuracy on training & test set \n",
    "\n",
    "def check_accuracy(loader, model):\n",
    "    if loader.dataset.train:\n",
    "        print(\"Checking accuracy on Train Data!!... \")\n",
    "    else:\n",
    "        print(\" Checking accuracy on Test Data!!  \")\n",
    "    \n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval() # let the model know that it is in evaluation mode\n",
    "    \n",
    "    # to let the model know that you dont have to compute the gradients while doing the tesing/accuracy checking\n",
    "    with torch.no_grad():\n",
    "        for x,y in loader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            \n",
    "#             x = x.reshape(x.shape[0], -1) # Flattening\n",
    "            \n",
    "            scores = model(x)\n",
    "            _, predictions = scores.max(1)\n",
    "            num_correct += (predictions == y).sum()\n",
    "            num_samples += predictions.size(0)\n",
    "            \n",
    "        # print('{}/{} with accuracy {}'.format(num_correct, num_samples, np.round(num_correct/num_samples, 2)))\n",
    "        \n",
    "    model.train() \n",
    "    return num_correct/num_samples\n",
    "    \n",
    "print(f\"Accuracy on training set: {check_accuracy(train_loader, model)*100:2f}\")\n",
    "print(f\"Accuracy on test set: {check_accuracy(test_loader, model)*100:.2f}\") \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f4f46f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
